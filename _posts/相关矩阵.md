

# y = Hx+w

![image-20211010143153326](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211010143153326.png)





# 信号x的相关矩阵Rx是多少

$$R_X$$

$$=E[xx^H]$$

$$=E[x(t)x^H(t)]$$

$$=E[|x(t)|^2]$$

Rx理论上是$$diag\{x^2(t_1),x^2(t_2),...,x^2(t_n)\}$$

实验验证结果：

当x是100，-100的序列时，统计估计的仿真结果为

![image-20211012123740473](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012123740473.png)

当x是$$+\sqrt{10}，-\sqrt{10}$$的序列时，统计估计的仿真结果为

![image-20211012123927963](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012123927963.png)

**理论值与仿真值相符，推导成立，即+x，-x等概率出现的随机信号的相关矩阵为$$diag\{x^2(t_1),x^2(t_2),...,x^2(t_n)\}$$**

# 噪声w的相关矩阵Rw是多少

$$R_W$$

$$=E[ww^H]$$

$$=E[w(t)w^H(t)]$$

$$=E[|w(t)|^2]$$

$$=\int_{-\infty} ^{+\infty}t^2f(t)dt$$

$$=\mu^2 +\delta^2$$

$$=I$$

Rw理论上是I

实验验证结果

![image-20211012124147072](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012124147072.png)

**理论值与仿真值相符，推导成立，即服从w~N（0，1）的高斯白噪声的相关矩阵为$$I$$**

# 信号y的相关矩阵Ry是多少

$$R_Y$$

$$=E[yy^H]$$

$$=E[(Hx(t)+w(t))(x^H(t)H^H+w^H(t))]$$

$$=E[Hx(t)x^H(t)H^H]+E[Hx(t)w^H(t)]+E[w(t)x^H(t)H^H]+E[w(t)w^H(t)]$$

因为噪声与信号是统计独立的，下式成立：

$$E[x_i(t)w_j^*(t)]=0,(i=1,2,...,P;j=1,2,...,M)$$

因此

$$R_Y$$

$$=E[Hx(t)x^H(t)H^H]+E[w(t)w^H(t)]$$

$$=HE[x(t)x^H(t)]A^H+E[w(t)w^H(t)]$$

$$=HR_xH^H+R_w$$

因为w是高斯白噪声，所以

$$R_Y=HR_xH^H+I$$



实验仿真

当x是$$+\sqrt{10}，-\sqrt{10}$$的序列时，

$$HRxH^H+I$$为

![image-20211012125306653](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012125306653.png)

统计估计的Ry为

![image-20211012124413372](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012124413372.png)

**理论值与仿真值相符，推导成立，即y的相关矩阵为$$R_Y=HR_xH^H+I$$**

# $$H^TH$$和$$HH^T$$的分解有啥不同？有啥相同

$$H$$是一个$$m×n$$的矩阵，其中$$m>n$$，$$H^TH$$是$$n×n$$矩阵，$$HH^T$$是$$m×m$$矩阵。

<img src="C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012131548038.png" alt="image-20211012131548038" style="zoom:50%;" />

$$H^TH=\left[\begin{array}{ccccc}
h_{0} & h_{1} & h_{2} & 0 & 0 & 0 & 0 \\
0 & h_{0} & h_{1} & h_{2} & 0 & 0 & 0\\
0 & 0 & h_{0} & h_{1} & h_{2} & 0 & 0\\
0 & 0 & 0 & h_{0} & h_{0} &h_{1} & h_{2} \\
0 & 0 & 0 & 0 & h_{1} & h_{1} & h_{2} 
\end{array}\right]·\left[\begin{array}{ccccc}
h_{0} & 0 & 0 & 0 & 0 \\
h_{1} & h_{0} & 0 & 0 & 0 \\
h_{2} & h_{1} & h_{0} & 0 & 0 \\
0 & h_{2} & h_{1} & h_{0} & 0 \\
0 & 0 & h_{2} & h_{1} & h_{0} \\
0 & 0 & 0 & h_{2} & h_{1} \\
0 & 0 & 0 & 0 & h_{2}
\end{array}\right]$$

$$H^TH=\left[\begin{array}{ccccc}
h_{0}^2 & h_{1}^2 & h_{2}^2 & 0 & 0 & 0 & 0 \\
0 & h_{0}^2 & h_{1}^2 & h_{2}^2 & 0 & 0 & 0\\
0 & 0 & h_{0} & h_{1} & h_{2}^2 & 0 & 0\\
0 888& 0 & 0 & h_{0} & h_{0} &h_{1} & h_{2} \\
0 & 0 & 0 & 0 & h_{1} & h_{1} & h_{2} 
\end{array}\right]$$





$$H^TH\Rightarrow H^TH·V=V·H^TH$$

$$HH^T\Rightarrow HH^T·V=V·HH^T$$

特征分解：


$$H^T*H$$=

    0.8100    0.3600    0.0800         0         0
    0.3600    0.8100    0.3600    0.0800         0
    0.0800    0.3600    0.8100    0.3600    0.0800
         0    0.0800    0.3600    0.8100    0.3600
         0         0    0.0800    0.3600    0.8100




vec1 =

    -0.2496     0.4716     0.5841   -0.5269    0.3107
     0.5037    -0.5269    -0.0475   -0.4716    0.4940
    -0.6066     0.0000    -0.5596   -0.0000    0.5647
     0.5037     0.5269    -0.0475    0.4716    0.4940
    -0.2496    -0.4716     0.5841    0.5269    0.3107


val1 =

    0.2780         0         0         0         0
         0    0.4078         0         0         0
         0         0    0.7041         0         0
         0         0         0    1.1322         0
         0         0         0         0    1.5279

$$H * H^T$$ =

    0.6400    0.3200    0.0800         0         0         0         0
    0.3200    0.8000    0.3600    0.0800         0         0         0
    0.0800    0.3600    0.8100    0.3600    0.0800         0         0
         0    0.0800    0.3600    0.8100    0.3600    0.0800         0
         0         0    0.0800    0.3600    0.8100    0.3600    0.0800
         0         0         0    0.0800    0.3600    0.1700    0.0400
         0         0         0         0    0.0800    0.0400    0.0100




vec2 =

     0.0014   -0.0070    0.3787    0.5908    0.5569   -0.3961    0.2011
     0.0011    0.0139   -0.5748   -0.3647    0.2332   -0.5526    0.4203
    -0.0155    0.0002    0.5856   -0.2562   -0.4865   -0.2268    0.5505
     0.0533   -0.1120   -0.3995    0.5776   -0.3177    0.3102    0.5424
    -0.0893    0.4459    0.1117   -0.2608    0.4676    0.5734    0.4066
    -0.0693   -0.8878    0.0938   -0.2129    0.2728    0.2424    0.1405
     0.9920   -0.0159    0.0473   -0.0738    0.0696    0.0495    0.0251


val2 =

     -0.0000       0         0         0         0         0         0
         0    0.0000         0         0         0         0         0
         0         0    0.2780         0         0         0         0
         0         0         0    0.4078         0         0         0
         0         0         0         0    0.7041         0         0
         0         0         0         0         0    1.1322         0
         0         0         0         0         0         0    1.5279



特征分解中$$H^TH$$和$$HH^T$$的非零特征值相同，











# 相关矩阵Ry的分解和$$HH^T$$的分解区别在哪



# 特征值和特征向量

* A是n阶方阵，如果数λ和n维非零向量v使得$$Av=λv$$(即$$(A−λE)x=0$$,转化成求解$$|A−λE|=0$$)成立，则称$$λ$$为A的特征值，向量$$v$$为A的对应特征值$$λ$$的特征向量。

* 对于$$Av=λv$$，可以看成矩阵A，向量v，系数λ这三者建立了一种联系，但显然我们无法通过式$$Av=λv$$来用v和λ表示 A，因为这个式子不是完备的，对于一个秩为m的矩阵A ，应该存在m个这样的式子，完备式子应该是：

$$A\left(\overrightarrow{v_{1}}, \overrightarrow{v_{2}}, \ldots, \overrightarrow{v_{m}}\right)=\left(\lambda_{1} \overrightarrow{v_{1}}, \lambda_{2} \overrightarrow{v_{2}}, \ldots, \lambda_{m} \overrightarrow{v_{m}}\right)=\left(\overrightarrow{v_{1}}, \overrightarrow{v_{2}}, \ldots, \overrightarrow{v_{m}}\right)\left[\begin{array}{ccc}
\lambda_{1} & \ldots & 0 \\
\ldots & \ldots & \ldots \\
0 & \ldots & \lambda_{m}
\end{array}\right]$$

$$AV=VΛ$$
这样就可以表示A了，$$A=VΛV^{−1}$$，即矩阵A被分解了。

![image-20211012131438076](C:\Users\JESSICA\AppData\Roaming\Typora\typora-user-images\image-20211012131438076.png)

# 随机变量的相关函数

* 相关函数是描述信号$$X(s)$$,$$Y(t)$$（这两个信号可以是随机的，也可以是确定的）在任意两个不同时刻$$s$$、$$t$$的取值之间的相关程度。

* 相关函数分为自相关函数和互相关函数

## 自相关函数

* 自相关函数是信号在时域中特性的平均度量，它用来描述随机信号$$x(t)$$在任意两个不同时刻$$s$$，$$t$$的取值之间的相关程度，其定义式为:$$R(s, t)=E(X(s) * X(t))$$

* 自相关矩阵定义为随机向量与自身的外积的数学期望：

$$R_{x} \stackrel{\text { def }}{\Rightarrow} E\left\{x(\omega) x^{H}(\omega)\right\}=\left[\begin{array}{ccc}
r_{11} & \cdots & r_{1 m} \\
\vdots & \ddots & \vdots \\
r_{m 1} & \cdots & r_{m m}
\end{array}\right]$$

其中，$$r_{ii}$$是随机变量$$x_{i}(\omega)$$的自相关系数，下标$$i=1,2,...,m$$，$$r_{i i}=E\left\{\left|x_{i}(\omega)\right|^{2}\right\}$$。

而$$r_{ij}$$是随机向量$$x_{i}(\omega)$$和$$x_{j}(\omega)$$ 的互相关系数，定义为：$$r_{i j}=E\left\{x_{i}(\omega) x_{j}(\omega)^{H}\right\}$$

显然，自相关矩阵是复共轭对称的，即为Hermitian矩阵。

# matlab的xcorr()函数

`r = xcorr(x)` 返回 `x` 的自相关序列。如果 `x` 是矩阵，则 `r` 也是矩阵，其中包含 `x` 的所有列组合的自相关和互相关序列。

`r = xcorr(x,y)` 返回两个离散时间序列的[互相关](https://ww2.mathworks.cn/help/matlab/ref/xcorr.html#mw_01b546db-b642-4f02-8625-16078810d80f)。互相关测量向量 `x` 和移位（滞后）副本向量 `y` 的之间的相似性，形式为滞后的函数。如果 `x` 和 `y` 的长度不同，函数会在较短向量的末尾添加零，使其长度与另一个向量相同。

# matlab产生随机数

**[randi](https://ww2.mathworks.cn/help/matlab/ref/randi.html) ：均匀分布的伪随机整数**

`X = randi(imax,sz1,...,szN)` 返回 `sz1`×...×`szN` 数组，其中 `sz1,...,szN` 指示每个维度的大小。例如，`randi(10,3,4)` 返回一个由介于 1 和 10 之间的伪随机整数组成的 3×4 数组。

例：产生+1，-1的随机数列。

```matlab
2*randi([0,1],row,col)-1
```

**[randn](https://ww2.mathworks.cn/help/matlab/ref/randn.html) :正态分布的随机数**

`X = randn(sz1,...,szN)` 返回由随机数组成的 `sz1`×...×`szN` 数组，其中 `sz1,...,szN` 指示每个维度的大小。例如：`randn(3,4)` 返回一个 3×4 的矩阵。

`X = randn(n)` 返回由正态分布的随机数组成的 `n`×`n` 矩阵。

例：产生高斯白噪声

```matlab
noise=randn(N,1)
```

